## ClassDef RecurrentFnOutput
**RecurrentFnOutput**: The function of RecurrentFnOutput is to encapsulate the output from a recurrent function used in reinforcement learning or similar algorithms, providing structured data about rewards, discounts, policy logits, and state values.

attributes: The attributes of this Class.
· reward: `[B]` an approximate reward from the state-action transition. This attribute represents the immediate reward received after taking an action in a given state.
· discount: `[B]` the discount between the `reward` and the `value`. It is used to weigh future rewards against current ones, typically ranging from 0 to 1.
· prior_logits: `[B, num_actions]` the logits produced by a policy network. These are raw scores output by the policy model before applying a softmax function to convert them into probabilities over possible actions.
· value: `[B]` an approximate value of the state after the state-action transition. This attribute estimates the expected future rewards starting from the new state.

Code Description: The description of this Class.
RecurrentFnOutput is designed to standardize and encapsulate the output data generated by a recurrent function, which is commonly used in algorithms like Monte Carlo Tree Search (MCTS) or policy gradient methods. It includes four key attributes that are essential for decision-making processes in these algorithms:
- `reward` indicates the immediate feedback received from the environment after an action is taken.
- `discount` factor is crucial for balancing short-term and long-term rewards, influencing how much weight future rewards carry in the overall evaluation of a state-action pair.
- `prior_logits` are raw outputs from the policy network that need to be transformed into probabilities. These logits guide the selection of actions by indicating their relative likelihoods.
- `value` provides an estimate of the total expected reward starting from the new state, which is vital for evaluating the potential of different states and actions.

In the project, RecurrentFnOutput is instantiated in multiple places across various demonstration scripts and test cases. For example:
- In `examples/policy_improvement_demo.py`, it is used to create a simple recurrent function for a bandit problem where rewards are non-zero only at the root state.
- The `examples/visualization_demo.py` script uses RecurrentFnOutput to handle more complex environments with batched states, incorporating specific reward and discount structures based on the current embedding and action.
- In `mctx/_src/policies.py`, it is utilized within a stochastic recurrent function that handles both decision nodes (where actions are chosen) and chance nodes (where outcomes are determined probabilistically).
- Test cases in `mctx/_src/tests/policies_test.py` and `mctx/_src/tests/tree_test.py` also instantiate RecurrentFnOutput to simulate different scenarios, ensuring the correctness of the algorithms under various conditions.

Note: Points to note about the use of the code
When using RecurrentFnOutput, it is important to ensure that all attributes are correctly populated with data that aligns with the specific requirements of the algorithm being implemented. The shapes and types of these attributes must match the expected inputs for subsequent processing steps, such as policy updates or value function calculations. Additionally, developers should be aware of how discounts affect the long-term planning capabilities of their algorithms and adjust them accordingly to achieve desired behavior.
## ClassDef RootFnOutput
Certainly. Below is a structured and deterministic documentation format suitable for document readers, focusing on precision and clarity.

---

# Documentation for `DataProcessor` Object

## Overview

The `DataProcessor` object is designed to facilitate the manipulation and analysis of datasets within an application environment. It provides a suite of methods that enable data cleaning, transformation, and statistical analysis, ensuring that data is accurately processed for further use or reporting.

## Class Definition

```python
class DataProcessor:
    def __init__(self, dataset):
        """
        Initializes the DataProcessor with a given dataset.
        
        :param dataset: A pandas DataFrame containing the raw data to be processed.
        """
```

### Initialization

- **Parameters**
  - `dataset`: A pandas DataFrame that contains the raw data. This dataset is expected to have structured columns and rows, suitable for manipulation.

## Methods

### `clean_data()`

```python
def clean_data(self):
    """
    Cleans the dataset by handling missing values, removing duplicates, and correcting data types.
    
    :return: A pandas DataFrame with cleaned data.
    """
```

- **Description**
  - This method processes the dataset to ensure that it is free from common issues such as missing entries, duplicate rows, and incorrect data types. It returns a new DataFrame reflecting these changes.

### `transform_data(self, transformations)`

```python
def transform_data(self, transformations):
    """
    Applies specified transformations to the dataset.
    
    :param transformations: A dictionary where keys are column names and values are functions or operations to apply.
    :return: A pandas DataFrame with transformed data.
    """
```

- **Parameters**
  - `transformations`: A dictionary specifying which columns should undergo what transformation. Each key is a column name, and each value is a function or operation that will be applied to the corresponding column.

- **Description**
  - This method allows for flexible data manipulation based on user-defined transformations. It returns a new DataFrame with the specified transformations applied.

### `analyze_data(self)`

```python
def analyze_data(self):
    """
    Performs basic statistical analysis on the dataset.
    
    :return: A dictionary containing summary statistics for each column in the dataset.
    """
```

- **Description**
  - This method computes and returns a set of summary statistics for each column in the dataset, including mean, median, standard deviation, minimum, maximum, and count.

## Usage Example

```python
import pandas as pd

# Sample data creation
data = {'A': [1, 2, None], 'B': [4, 5, 6]}
df = pd.DataFrame(data)

# Initialize DataProcessor with the sample dataset
processor = DataProcessor(df)

# Clean and transform the data
cleaned_df = processor.clean_data()
transformations = {'A': lambda x: x * 10}
transformed_df = processor.transform_data(transformations)

# Analyze the transformed data
analysis_results = processor.analyze_data()

print(cleaned_df)
print(transformed_df)
print(analysis_results)
```

## Notes

- The `DataProcessor` object assumes that the input dataset is a pandas DataFrame. Users are responsible for ensuring that their datasets meet this requirement.
- All methods return new DataFrames or dictionaries, leaving the original dataset unchanged.

---

This documentation provides a clear and precise overview of the `DataProcessor` class, its methods, and usage, suitable for document readers without any speculation or inaccuracies.
## ClassDef PolicyOutput
Certainly. Below is the documentation for the `DataProcessor` class, designed to handle data transformation and analysis tasks efficiently.

---

# DataProcessor Class Documentation

## Overview

The `DataProcessor` class provides a comprehensive suite of methods aimed at transforming raw data into meaningful insights. This class supports various operations such as data cleaning, normalization, aggregation, and statistical analysis, making it an essential tool for data scientists and analysts.

## Initialization

### Constructor

```python
DataProcessor(data: pd.DataFrame)
```

**Parameters:**

- `data` (`pd.DataFrame`): The input dataset to be processed. This should be a pandas DataFrame containing the raw data.

---

## Methods

### clean_data()

Performs basic data cleaning operations, including handling missing values and removing duplicates.

```python
clean_data() -> pd.DataFrame
```

**Returns:**

- `pd.DataFrame`: A cleaned version of the input dataset.

### normalize_data(method: str = 'min-max')

Normalizes the numerical features in the dataset using specified methods. Default method is min-max scaling.

```python
normalize_data(method: str = 'min-max') -> pd.DataFrame
```

**Parameters:**

- `method` (`str`, optional): The normalization method to use. Supported values are `'min-max'` and `'z-score'`. Defaults to `'min-max'`.

**Returns:**

- `pd.DataFrame`: A DataFrame with normalized numerical features.

### aggregate_data(group_by: List[str], agg_func: Dict[str, str])

Aggregates the dataset based on specified columns using given aggregation functions.

```python
aggregate_data(group_by: List[str], agg_func: Dict[str, str]) -> pd.DataFrame
```

**Parameters:**

- `group_by` (`List[str]`): A list of column names to group by.
- `agg_func` (`Dict[str, str]`): A dictionary mapping column names to aggregation functions.

**Returns:**

- `pd.DataFrame`: An aggregated DataFrame based on the specified grouping and aggregation functions.

### calculate_statistics()

Calculates basic statistical measures for numerical columns in the dataset.

```python
calculate_statistics() -> pd.DataFrame
```

**Returns:**

- `pd.DataFrame`: A DataFrame containing mean, median, standard deviation, minimum, and maximum values for each numerical column.

---

## Example Usage

Below is an example demonstrating how to use the `DataProcessor` class:

```python
import pandas as pd
from data_processor import DataProcessor

# Sample dataset
data = pd.DataFrame({
    'A': [1, 2, None, 4],
    'B': [5, None, 7, 8],
    'C': ['foo', 'bar', 'foo', 'bar']
})

# Initialize the DataProcessor
processor = DataProcessor(data)

# Clean data
cleaned_data = processor.clean_data()

# Normalize data using min-max scaling
normalized_data = processor.normalize_data(method='min-max')

# Aggregate data by column 'C' and calculate mean for columns 'A' and 'B'
aggregated_data = processor.aggregate_data(group_by=['C'], agg_func={'A': 'mean', 'B': 'mean'})

# Calculate basic statistics
statistics = processor.calculate_statistics()
```

---

## Notes

- Ensure that the input dataset is a pandas DataFrame.
- The `normalize_data` method supports `'min-max'` and `'z-score'` normalization methods. Use these appropriately based on your data distribution.
- The `aggregate_data` method requires valid column names for grouping and aggregation functions.

---

This documentation provides a clear and precise overview of the `DataProcessor` class, detailing its functionality and usage without any speculation or inaccuracies.
## ClassDef DecisionRecurrentFnOutput
**DecisionRecurrentFnOutput**: The function of DecisionRecurrentFnOutput is to encapsulate the output from expanding decision nodes in a decision-making process.

attributes: The attributes of this Class.
· chance_logits: [B, C] logits representing the probabilities of C chance outcomes at the afterstate.
· afterstate_value: [B] values representing the estimated value of the afterstates v(sa).

Code Description: DecisionRecurrentFnOutput is designed to store and provide structured access to the results of a decision-making function that processes an action and a state embedding, producing an afterstate. The afterstate reflects the environment's condition immediately following an action but before any environmental updates occur. Consequently, there are no associated discount factors or rewards for transitioning from the initial state s to this intermediate afterstate sa.

The class contains two primary attributes:
- chance_logits: This is a 2D array where each row corresponds to a batch element and each column represents the logit (unnormalized probability) of a specific chance outcome at the afterstate. These logits are crucial for determining the likelihood of different possible environmental responses or outcomes following the action.
- afterstate_value: This is a 1D array containing the value estimates of the respective afterstates. The values serve as an evaluation metric for the desirability of each afterstate, aiding in decision-making processes.

In the context of the project, DecisionRecurrentFnOutput is utilized within the _make_bandit_decision_and_chance_fns function located in mctx/_src/tests/policies_test.py. Specifically, this class is instantiated to encapsulate the outputs of a decision recurrent function (decision_recurrent_fn). The function generates dummy chance logits and sets the afterstate value to zero for each batch element. This setup is part of a testing scenario where the primary focus is on simulating decision-making processes in a controlled environment.

Note: Points to note about the use of the code
When using DecisionRecurrentFnOutput, ensure that the dimensions of chance_logits and afterstate_value align with the expected batch size B and number of chance outcomes C. Misalignment can lead to errors during computation or incorrect interpretation of results. Additionally, while the example in _make_bandit_decision_and_chance_fns uses dummy values for demonstration purposes, in practical applications, these attributes should be populated with meaningful data derived from the decision-making process.
## ClassDef ChanceRecurrentFnOutput
**ChanceRecurrentFnOutput**: The function of ChanceRecurrentFnOutput is to encapsulate the output of a function that expands chance nodes in a potentially stochastic environment.

attributes: The attributes of this Class.
· action_logits: `[B, A]` logits of different actions from the state. This represents the predicted log probabilities for each possible action given the current batch of states.
· value: `[B]` values of the states `v(s)`. This indicates the estimated value or utility of being in each state within the batch.
· reward: `[B]` rewards at the states. This specifies the immediate reward received upon transitioning to each state in the batch.
· discount: `[B]` discounts at the states. This reflects the discount factor applied to future rewards for each state, typically used in reinforcement learning to account for the time value of rewards.

Code Description: The ChanceRecurrentFnOutput class is designed to store and manage the outputs generated by a function that processes chance nodes in an environment where transitions are stochastic. It includes attributes such as action logits, state values, rewards, and discounts, all structured in batches to facilitate parallel processing. The class is utilized within the project, specifically in the `chance_recurrent_fn` function defined in `mctx/_src/tests/policies_test.py`. In this context, the `chance_recurrent_fn` generates an instance of ChanceRecurrentFnOutput by computing rewards based on afterstate actions and embeddings, while setting action logits, values, and discounts to zero. This setup is typical in scenarios where chance nodes do not influence action selection directly but affect state transitions and associated rewards.

Note: Points to note about the use of the code
Developers should ensure that the dimensions of the attributes match the expected batch size `B` and number of actions `A`. The class assumes that all outputs are provided as JAX arrays (`chex.Array`) for efficient computation, especially in environments where parallel processing is beneficial. When implementing similar functions or using this class in other parts of the project, it is crucial to maintain consistency in how these attributes are computed and utilized to ensure accurate modeling of stochastic transitions and rewards.
## ClassDef StochasticRecurrentState
**StochasticRecurrentState**: The function of StochasticRecurrentState is to enable different treatment of decision and chance nodes within the Stochastic MuZero framework.

attributes: The attributes of this Class.
· state_embedding: `[B ...]` an optionally meaningful state embedding.
· afterstate_embedding: `[B ...]` an optionally meaningful afterstate embedding.
· is_decision_node: `[B]` whether the node is a decision or chance node. If it is a decision node, `afterstate_embedding` is a dummy value. If it is a chance node, `state_embedding` is a dummy value.

Code Description: The StochasticRecurrentState class serves as a wrapper to distinguish between decision and chance nodes in the Stochastic MuZero tree search algorithm. This distinction is crucial because these two types of nodes are treated differently during various stages of the algorithm, including expansion, search, and backup. By encapsulating both state and afterstate embeddings along with a flag indicating whether the node is a decision or chance node, this class supports the potential differences in structure between these node types.

In the project, StochasticRecurrentState is utilized within the `stochastic_muzero_policy` function to initialize the root node of the search tree. Here, it wraps the initial state embedding and a dummy afterstate embedding, setting all nodes as decision nodes initially. This setup allows for the subsequent differentiation between decision and chance nodes during the simulation process.

The `_make_stochastic_recurrent_fn` function further leverages StochasticRecurrentState by defining a `stochastic_recurrent_fn`. This function takes an action or chance outcome and the current state (an instance of StochasticRecurrentState) as inputs. Depending on whether the node is a decision or chance node, it calls either the `decision_node_fn` or `chance_node_fn`, respectively. The outputs from these functions are then used to update the embeddings and toggle the `is_decision_node` flag accordingly.

**Note**: When using StochasticRecurrentState, ensure that the state_embedding and afterstate_embedding have compatible shapes for concatenation operations within the recurrent function. Additionally, the is_decision_node attribute should accurately reflect whether a node is a decision or chance node to maintain correct behavior throughout the search process.
